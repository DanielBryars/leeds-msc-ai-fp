# Glossary

- **RepRTA** (Re‑parameterizable Region‑Text Alignment),
    
- **SAVPE** (Semantic‑Activated Visual Prompt Encoder),
    
- **LRPC** (Lazy Region‑Prompt Contrast) for prompt‑free detectio


**AnyDexGrasp** — A two-stage learning approach for dexterous grasping, using contact-centric grasp representations (CGRs) for hand-agnostic training and hand-specific adaptation.

**ControlVLA** — A framework for few-shot object-centric adaptation of pre-trained Vision-Language-Action (VLA) models for efficient robotic manipulation.

**Cross-Bin Inference** — Using multiple partial views of the same item from different bins to improve recognition, reconstruction, or grasp prediction.

**NeRFs (Neural Radiance Fields)** — A method for representing and reconstructing 3D scenes from limited views using implicit volumetric representations.

**Object Depth Mapping (ODM)** — Technique that fuses RGB object masks with depth information to create simplified, object-centric spatial maps.

**ObjectVLA** — A vision-language-action framework for zero-shot object generalization via localization-aware reasoning.

**PhotoNeo RGB-D Camera** — A high-precision depth and RGB camera system used for industrial robotic perception.

**RCANs (Randomized-to-Canonical Adaptation Networks)** — Sim-to-real technique that maps randomized simulated images to canonical forms, improving transfer to real-world data.

**RoboTwin 2.0** — A simulation framework for large-scale data generation with strong domain randomization for robotic manipulation tasks.

**Sim-to-Real Transfer** — Methods for improving the real-world performance of models trained in simulation by bridging the 'reality gap'.

**U-Net** — A convolutional neural network architecture widely used for segmentation and grasp region prediction in robotics.

**XYZ-IBD Dataset** — An industrial bin-picking dataset featuring texture-less, metallic, and symmetrical objects with severe clutter and occlusion.

